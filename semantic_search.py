#!/usr/bin/env python3
"""
Semantic search using embeddings.
Search through a collection of texts using natural language queries.
"""

import os
import sys
import json
import numpy as np
from openai import OpenAI

def cosine_similarity(vec1, vec2):
    """Calculate cosine similarity between two vectors."""
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

def main():
    # Check if API key is set
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("ERROR: OPENAI_API_KEY environment variable not set!")
        sys.exit(1)
    
    # Get arguments
    if len(sys.argv) < 3:
        print("Usage: python semantic_search.py <embeddings_file> <query> [top_k]")
        print("\nExamples:")
        print('  python semantic_search.py embeddings.json "machine learning"')
        print('  python semantic_search.py embeddings.json "python programming" 5')
        print("\nFirst generate embeddings using batch_embeddings.py")
        sys.exit(1)
    
    embeddings_file = sys.argv[1]
    query = sys.argv[2]
    top_k = int(sys.argv[3]) if len(sys.argv) > 3 else 5
    
    # Check if embeddings file exists
    if not os.path.exists(embeddings_file):
        print(f"ERROR: Embeddings file '{embeddings_file}' not found!")
        print("Generate it first using: python batch_embeddings.py <input_file>")
        sys.exit(1)
    
    try:
        print("=" * 70)
        print("Semantic Search")
        print("=" * 70)
        
        # Load embeddings
        print(f"\nLoading embeddings from: {embeddings_file}")
        with open(embeddings_file, 'r') as f:
            data = json.load(f)
        
        model = data["model"]
        embeddings = data["embeddings"]
        
        print(f"Loaded {len(embeddings)} embeddings")
        print(f"Model: {model}")
        print(f"Query: {query}")
        print("\nGenerating query embedding...")
        
        # Initialize OpenAI client
        client = OpenAI(api_key=api_key)
        
        # Generate embedding for query
        response = client.embeddings.create(
            model=model,
            input=query
        )
        
        query_embedding = response.data[0].embedding
        
        # Calculate similarities
        print("Calculating similarities...")
        similarities = []
        for item in embeddings:
            similarity = cosine_similarity(query_embedding, item["embedding"])
            similarities.append({
                "text": item["text"],
                "similarity": similarity,
                "index": item.get("index", 0)
            })
        
        # Sort by similarity
        similarities.sort(key=lambda x: x["similarity"], reverse=True)
        
        # Display top results
        print("\n" + "=" * 70)
        print(f"Top {top_k} Results:")
        print("=" * 70)
        
        for i, result in enumerate(similarities[:top_k], 1):
            print(f"\n{i}. [Similarity: {result['similarity']:.4f} ({result['similarity']*100:.2f}%)]")
            print(f"   {result['text']}")
        
        print("\n" + "=" * 70)
        
    except json.JSONDecodeError:
        print(f"ERROR: Invalid JSON in embeddings file")
        sys.exit(1)
    except KeyError as e:
        print(f"ERROR: Missing key in embeddings file: {e}")
        print("Make sure the file was generated by batch_embeddings.py")
        sys.exit(1)
    except Exception as e:
        print(f"ERROR: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

